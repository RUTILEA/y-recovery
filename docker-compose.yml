version: '3.8'

services:
  backend:
    image: ubuntu:22.04
    build:
      context: .
      dockerfile: Dockerfile-dev
    container_name: yuasa-server
    volumes:
      - .:/workspace
      - H:\GYHD10176:/workspace/data
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
    # deploy:
      # resources:
      #   reservations:
      #     devices:
      #       - capabilities: [gpu]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    stdin_open: true  # Keep STDIN open even if not attached
    tty: true  # Allocate a pseudo-TTY